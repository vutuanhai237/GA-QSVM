{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "import itertools\n",
    "import wandb\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "# QOOP-specific imports\n",
    "from qoop.evolution import normalizer\n",
    "from qoop.evolution.environment_synthesis import MetadataSynthesis\n",
    "from qoop.evolution.generator import by_num_rotations_and_cnot\n",
    "from qoop.evolution.environment import EEnvironment\n",
    "from qoop.evolution.crossover import onepoint\n",
    "from qoop.evolution.mutate import bitflip_mutate_with_normalizer\n",
    "from qoop.evolution.threshold import synthesis_threshold\n",
    "from qoop.backend.constant import operations_with_rotations\n",
    "from qoop.evolution import divider\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from squlearn.kernel.qsvc import QSVC as PQSVC\n",
    "from squlearn.kernel.lowlevel_kernel import ProjectedQuantumKernel\n",
    "from squlearn import Executor\n",
    "from squlearn.encoding_circuit import QiskitEncodingCircuit\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "# RANDOM_SEED = 42\n",
    "# np.random.seed(RANDOM_SEED)\n",
    "# random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'digits-N10-Cnot5-D10-C16-g200-p*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! ls -dt1 digits-N10-Cnot5-D10-C16-g200-p*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits-N6-Cnot3-D6-C20-g200-p0.02154 có tính chất kì lạ. circuit 1 thì ra đầy đủ entanglement các thứ nhưng sau khi tiến hoá thì ra được cái mạch không hề có entanglement. Tức là data này có thể solve một cách linearly được. Và kết quả ra rất tốt 0.79 kém max 0.01. Và thậm chí nó còn không dùng 1 qubits còn lại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">          ┌──────────────┐                                \n",
       "q_0: ──■──┤ Rz(theta[6]) ├────────────────────────────────\n",
       "       │  ├──────────────┤┌──────────────┐┌──────────────┐\n",
       "q_1: ──┼──┤ Rz(theta[0]) ├┤ Ry(theta[3]) ├┤ Ry(theta[9]) ├\n",
       "       │  └──────────────┘└──────────────┘└──────────────┘\n",
       "q_2: ──┼──────────────────────────────────────────────────\n",
       "       │  ┌──────────────┐                                \n",
       "q_3: ──┼──┤ Ry(theta[4]) ├────────────────────────────────\n",
       "       │  └──────────────┘                                \n",
       "q_4: ──┼──────────────────────────────────────────────────\n",
       "       │  ┌──────────────┐┌──────────────┐                \n",
       "q_5: ──┼──┤ Ry(theta[7]) ├┤ Rz(theta[8]) ├────────────────\n",
       "       │  └──────────────┘└──────────────┘                \n",
       "q_6: ──┼──────────────────────────────────────────────────\n",
       "       │  ┌──────────────┐                                \n",
       "q_7: ──┼──┤ Ry(theta[1]) ├────────────────────────────────\n",
       "       │  ├──────────────┤                                \n",
       "q_8: ──┼──┤ Rx(theta[2]) ├────────────────────────────────\n",
       "     ┌─┴─┐├──────────────┤                                \n",
       "q_9: ┤ X ├┤ Ry(theta[5]) ├────────────────────────────────\n",
       "     └───┘└──────────────┘                                </pre>"
      ],
      "text/plain": [
       "          ┌──────────────┐                                \n",
       "q_0: ──■──┤ Rz(theta[6]) ├────────────────────────────────\n",
       "       │  ├──────────────┤┌──────────────┐┌──────────────┐\n",
       "q_1: ──┼──┤ Rz(theta[0]) ├┤ Ry(theta[3]) ├┤ Ry(theta[9]) ├\n",
       "       │  └──────────────┘└──────────────┘└──────────────┘\n",
       "q_2: ──┼──────────────────────────────────────────────────\n",
       "       │  ┌──────────────┐                                \n",
       "q_3: ──┼──┤ Ry(theta[4]) ├────────────────────────────────\n",
       "       │  └──────────────┘                                \n",
       "q_4: ──┼──────────────────────────────────────────────────\n",
       "       │  ┌──────────────┐┌──────────────┐                \n",
       "q_5: ──┼──┤ Ry(theta[7]) ├┤ Rz(theta[8]) ├────────────────\n",
       "       │  └──────────────┘└──────────────┘                \n",
       "q_6: ──┼──────────────────────────────────────────────────\n",
       "       │  ┌──────────────┐                                \n",
       "q_7: ──┼──┤ Ry(theta[1]) ├────────────────────────────────\n",
       "       │  ├──────────────┤                                \n",
       "q_8: ──┼──┤ Rx(theta[2]) ├────────────────────────────────\n",
       "     ┌─┴─┐├──────────────┤                                \n",
       "q_9: ┤ X ├┤ Ry(theta[5]) ├────────────────────────────────\n",
       "     └───┘└──────────────┘                                "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit.qpy import dump, load\n",
    "n_features = 10\n",
    "data_name = \"fashion\"\n",
    "home = '/home/qsvm/test/GA-QSVM/'\n",
    "folder = 'PQK-fashion-N10-Cnot30-D100-C16-g200-p0.1'\n",
    "with open(home + folder + '/best_circuit_163.qpy', 'rb') as f:\n",
    "    loaded_circuits = load(f) # qpy.load returns a list of circuits\n",
    "\n",
    "qc_loaded = loaded_circuits[0]\n",
    "qc_loaded.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_vec = [0, 1, 0, 0, 0, 0]\n",
    "# y_vec = [0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "# from qiskit.primitives import Sampler\n",
    "# fidelity = ComputeUncompute(sampler=Sampler())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuit = fidelity.create_fidelity_circuit(qc_loaded, qc_loaded)\n",
    "# # circuit.draw(output='mpl')\n",
    "# bound_circuit = circuit.assign_parameters(np.concatenate([x_vec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposed_circuit = bound_circuit.decompose()\n",
    "# decomposed_circuit.draw(\"mpl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of qubits in loaded circuit: 10\n",
      "Number of parameters in loaded circuit: 10\n",
      "Parameters: ParameterView([ParameterVectorElement(theta[0]), ParameterVectorElement(theta[1]), ParameterVectorElement(theta[2]), ParameterVectorElement(theta[3]), ParameterVectorElement(theta[4]), ParameterVectorElement(theta[5]), ParameterVectorElement(theta[6]), ParameterVectorElement(theta[7]), ParameterVectorElement(theta[8]), ParameterVectorElement(theta[9])])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of qubits in loaded circuit: {qc_loaded.num_qubits}\")\n",
    "print(f\"Number of parameters in loaded circuit: {qc_loaded.num_parameters}\")\n",
    "print(\"Parameters:\", qc_loaded.parameters) # Shows the Parameter objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 21:19:21.320651: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-11 21:19:21.349585: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-11 21:19:21.349613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-11 21:19:21.350832: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-11 21:19:21.355748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine, load_digits, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "# Load cancer data using the function from data/split.py\n",
    "# Number of features should match the number of qubits in the quantum circuit\n",
    "training_size = 100\n",
    "test_size = 100\n",
    "\n",
    "\n",
    "def prepare_cancer_data_split(training_size, test_size, n_features, random_state):\n",
    "    digits = load_breast_cancer()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=100,train_size=100, random_state=random_state, stratify=digits.target)\n",
    "    \n",
    "    # Scale the features \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Reduce dimensionality using PCA\n",
    "    pca = PCA(n_components=n_features)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    \n",
    "    print(f\"Training size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def prepare_wine_data_split(training_size, test_size, n_features, random_state=20):\n",
    "    wine = load_wine()\n",
    "    X, y = wine.data, wine.target\n",
    "\n",
    "    # Split data into training and testing sets BEFORE scaling/PCA\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=100, test_size=78, random_state=random_state, shuffle=True, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"Split complete. Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "    # Scale the features (Fit on training data only!)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test) # Transform test data using training scaler\n",
    "\n",
    "    pca = PCA(n_components=n_features) \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test) # Transform test data using training PCA\n",
    "\n",
    "    print(f\"PCA complete. Number of features: {X_train.shape[1]}\")\n",
    "    print(f\"Final Training size: {len(X_train)}, Final Test size: {len(X_test)}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def prepare_digits_data_split(training_size, test_size, n_features, binary=False, random_state=55):\n",
    "    digits = load_digits()\n",
    "    X, y = shuffle(digits.data, digits.target, random_state=random_state)\n",
    "\n",
    "    # Split data into training and testing sets BEFORE scaling/PCA\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=100, test_size=100, random_state=random_state, shuffle=True, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"Split complete. Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "    # std_scaler = StandardScaler()\n",
    "    # X_train = std_scaler.fit_transform(X_train)\n",
    "    # X_test = std_scaler.transform(X_test)\n",
    "\n",
    "    # Scale the features (Fit on training data only!)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test) # Transform test data using training scaler\n",
    "\n",
    "    # Reduce dimensionality using PCA (Fit on training data only!)\n",
    "    # Add random_state to PCA if using randomized solvers like 'arpack' or 'randomized'\n",
    "    pca = PCA(n_components=n_features, random_state=random_state) \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test) # Transform test data using training PCA\n",
    "\n",
    "    print(f\"PCA complete. Number of features: {X_train.shape[1]}\")\n",
    "    print(f\"Final Training size: {len(X_train)}, Final Test size: {len(X_test)}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def prepare_fashion_mnist_data_split(training_size, test_size, n_features, binary=False, random_state=55):\n",
    "    # Load Fashion MNIST dataset\n",
    "    (X_train_full, y_train_full), (X_test_full, y_test_full) = fashion_mnist.load_data()\n",
    "    \n",
    "    # Combine training and test sets\n",
    "    X = np.concatenate([X_train_full, X_test_full], axis=0)\n",
    "    y = np.concatenate([y_train_full, y_test_full], axis=0)\n",
    "    \n",
    "    # Reshape from 28x28 images to flat vectors (784 features)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    \n",
    "    # Convert to float and normalize to 0-1 range\n",
    "    X = X.astype('float32') / 255.0\n",
    "    \n",
    "    # Shuffle the data\n",
    "    X, y = shuffle(X, y, random_state=random_state)\n",
    "\n",
    "    # Filter for binary classification if requested\n",
    "    if binary:\n",
    "        mask = (y == 0) | (y == 1)  # T-shirt/top vs Trouser\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        # Convert to binary labels (-1 for class 0, 1 for class 1)\n",
    "        y = 2 * (y == 1) - 1  # Converts 0 -> -1 and 1 -> 1\n",
    "        print(f\"Filtered for binary classification (T-shirt/top vs Trouser). Data shape: {X.shape}\")\n",
    "    else:\n",
    "        print(f\"Using multiclass classification (10 fashion categories). Data shape: {X.shape}\")\n",
    "\n",
    "    # Split data into training and testing sets BEFORE scaling/PCA\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=training_size, test_size=test_size, random_state=random_state, shuffle=True, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"Split complete. Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "    # Scale the features (Fit on training data only!)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test) # Transform test data using training scaler\n",
    "\n",
    "    # Reduce dimensionality using PCA (Fit on training data only!)\n",
    "    # Add random_state to PCA if using randomized solvers like 'arpack' or 'randomized'\n",
    "    pca = PCA(n_components=n_features, random_state=random_state) \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test) # Transform test data using training PCA\n",
    "\n",
    "    print(f\"PCA complete. Number of features: {X_train.shape[1]}\")\n",
    "    print(f\"Final Training size: {len(X_train)}, Final Test size: {len(X_test)}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "dataset = {'digits': prepare_digits_data_split, 'wine': prepare_wine_data_split, 'cancer': prepare_cancer_data_split, 'fashion': prepare_fashion_mnist_data_split}\n",
    "data = dataset[data_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data import prepare_digits_data_split, prepare_wine_data_split, prepare_cancer_data_split\n",
    "\n",
    "# dataset = {'digits': prepare_digits_data_split, 'wine': prepare_wine_data_split, 'cancer': prepare_cancer_data_split}\n",
    "# data = dataset[data_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 10\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Quantum SVM with the loaded 7-qubit circuit...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.2600 (26.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 10\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Quantum SVM with the loaded 7-qubit circuit...\n",
      "Classification accuracy: 0.1600 (16.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 10\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Quantum SVM with the loaded 7-qubit circuit...\n",
      "Classification accuracy: 0.2000 (20.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 10\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Quantum SVM with the loaded 7-qubit circuit...\n",
      "Classification accuracy: 0.2300 (23.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 10\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Quantum SVM with the loaded 7-qubit circuit...\n",
      "Classification accuracy: 0.2200 (22.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 10\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Quantum SVM with the loaded 7-qubit circuit...\n",
      "Classification accuracy: 0.2400 (24.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 10\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Quantum SVM with the loaded 7-qubit circuit...\n"
     ]
    }
   ],
   "source": [
    "from qiskit.circuit.library import ZFeatureMap, ZZFeatureMap\n",
    "\n",
    "# data = dataset[data_name]\n",
    "results_all = {}\n",
    "for n_features in range(10, 11):\n",
    "    results = []\n",
    "    for i in range(100,110):\n",
    "    # for i in range(1000, 1020):\n",
    "\n",
    "        # Load and prepare cancer dataset\n",
    "        X_train, X_test, y_train, y_test = data(\n",
    "            training_size=training_size, \n",
    "            test_size=test_size, \n",
    "            n_features=n_features, \n",
    "            random_state=i\n",
    "        )\n",
    "\n",
    "        # Training function adapted from main.py to work with our loaded data\n",
    "        def train_qsvm(quantum_circuit):\n",
    "            \"\"\"\n",
    "            Train Fidelity Quantum SVM\n",
    "            \n",
    "            Args:\n",
    "                quantum_circuit: Quantum circuit to use as feature map\n",
    "            \n",
    "            Returns:\n",
    "                Classification accuracy and a custom metric\n",
    "            \"\"\"\n",
    "            quantum_kernel = FidelityQuantumKernel(feature_map=quantum_circuit)\n",
    "            qsvc = QSVC(quantum_kernel=quantum_kernel)\n",
    "            qsvc.fit(X_train, y_train)\n",
    "            y_pred = qsvc.predict(X_test)\n",
    "            return accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Train the QSVM with the loaded quantum circuit\n",
    "        print(\"Training Quantum SVM with the loaded 7-qubit circuit...\")\n",
    "        qc_loaded = ZFeatureMap(feature_dimension=n_features)\n",
    "        accuracy = train_qsvm(qc_loaded)\n",
    "        results.append(accuracy)\n",
    "        print(f\"Classification accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "    # print(results)\n",
    "    results_all[n_features] = np.mean(results)\n",
    "\n",
    "print(results_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create ZFeatureMap circuit\n",
    "# from qiskit.circuit.library import ZFeatureMap\n",
    "\n",
    "# # Initialize ZFeatureMap with same number of features as data\n",
    "# zfm = ZFeatureMap(feature_dimension=n_features)\n",
    "\n",
    "# results_zfm = []\n",
    "# # for i in range(1000, 1020):\n",
    "# for i in range(100,110):\n",
    "    \n",
    "#     # Load and prepare dataset\n",
    "#     X_train, X_test, y_train, y_test = data(\n",
    "#         training_size=training_size, \n",
    "#         test_size=test_size, \n",
    "#         n_features=n_features, \n",
    "#         random_state=i\n",
    "#     )\n",
    "\n",
    "#     # Train QSVM with ZFeatureMap\n",
    "#     print(\"Training Quantum SVM with ZFeatureMap circuit...\")\n",
    "#     quantum_kernel = FidelityQuantumKernel(feature_map=zfm)\n",
    "#     qsvc = QSVC(quantum_kernel=quantum_kernel)\n",
    "#     qsvc.fit(X_train, y_train)\n",
    "#     y_pred = qsvc.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     results_zfm.append(accuracy)\n",
    "#     print(f\"Classification accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# print(\"Average accuracy with ZFeatureMap:\", np.mean(results_zfm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create ZZFeatureMap circuit\n",
    "# from qiskit.circuit.library import ZZFeatureMap\n",
    "\n",
    "# # Initialize ZZFeatureMap with same number of features as data\n",
    "# zzfm = ZZFeatureMap(feature_dimension=n_features)\n",
    "\n",
    "# results_zzfm = []\n",
    "# # for i in range(1000, 1020):\n",
    "# for i in range(100,110):\n",
    "#     # Load and prepare dataset\n",
    "#     X_train, X_test, y_train, y_test = data(\n",
    "#         training_size=training_size, \n",
    "#         test_size=test_size, \n",
    "#         n_features=n_features, \n",
    "#         random_state=i\n",
    "#     )\n",
    "\n",
    "#     # Train QSVM with ZZFeatureMap\n",
    "#     print(\"Training Quantum SVM with ZZFeatureMap circuit...\")\n",
    "#     quantum_kernel = FidelityQuantumKernel(feature_map=zzfm)\n",
    "#     qsvc = QSVC(quantum_kernel=quantum_kernel)\n",
    "#     qsvc.fit(X_train, y_train)\n",
    "#     y_pred = qsvc.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     results_zzfm.append(accuracy)\n",
    "#     print(f\"Classification accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# print(\"Average accuracy with ZZFeatureMap:\", np.mean(results_zzfm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.6400 (64.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.6400 (64.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.6900 (69.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.6500 (65.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.6900 (69.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.6500 (65.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.6400 (64.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.6300 (63.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.7000 (70.00%)\n",
      "Using multiclass classification (10 fashion categories). Data shape: (70000, 784)\n",
      "Split complete. Training samples: 100, Test samples: 100\n",
      "PCA complete. Number of features: 11\n",
      "Final Training size: 100, Final Test size: 100\n",
      "Training Classical SVM with RBF kernel...\n",
      "Classification accuracy: 0.6500 (65.00%)\n",
      "Average accuracy with RBF kernel: 0.6580000000000001\n"
     ]
    }
   ],
   "source": [
    "# # Train classical SVM with RBF kernel\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "results_rbf = []\n",
    "# for i in range(1000, 1020):\n",
    "for i in range(100,110):\n",
    "    \n",
    "    # Load and prepare dataset\n",
    "    X_train, X_test, y_train, y_test = data(\n",
    "        training_size=training_size, \n",
    "        test_size=test_size, \n",
    "        n_features=11, \n",
    "        random_state=i\n",
    "    )\n",
    "\n",
    "    # Train SVM with RBF kernel\n",
    "    print(\"Training Classical SVM with RBF kernel...\")\n",
    "    svc = SVC(kernel='rbf')\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results_rbf.append(accuracy)\n",
    "    print(f\"Classification accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"Average accuracy with RBF kernel:\", np.mean(results_rbf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cutn-qsvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
