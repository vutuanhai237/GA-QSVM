{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44876254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "from matplotlib.colors import ListedColormap\n",
    "from pennylane import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_wine, load_digits, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37364dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_digits_data_split(train_size, test_size, n_features, binary=False, random_state=23):\n",
    "    \"\"\"\n",
    "    Prepare Digits dataset with a standard train/test split and preprocessing.\n",
    "\n",
    "    Args:\n",
    "        train_size (float or int): If float, should be between 0.0 and 1.0 and represent the\n",
    "                                 proportion of the dataset to include in the train split.\n",
    "                                 If int, represents the absolute number of train samples.\n",
    "        n_features (int): Number of features to reduce to using PCA.\n",
    "        binary (bool): If True, filter for digits 0 and 1, convert labels to -1 and 1.\n",
    "                       If False (default), use all digits 0-9.\n",
    "        random_state (int): Controls the shuffling applied to the data before splitting and\n",
    "                           the split itself for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Preprocessed training and testing datasets (X_train, X_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    # Load Digits Dataset\n",
    "    digits = load_digits()\n",
    "    \n",
    "    # Shuffle dataset once initially (optional, as train_test_split can shuffle)\n",
    "    # Using shuffle here ensures the same shuffling logic as the original if needed downstream,\n",
    "    # but train_test_split's shuffle=True is generally sufficient.\n",
    "    X, y = shuffle(digits.data, digits.target, random_state=random_state)\n",
    "\n",
    "    # Filter for binary classification if requested\n",
    "    if binary:\n",
    "        mask = (y == 0) | (y == 1)\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        # Convert to binary labels (-1 for class 0, 1 for class 1)\n",
    "        y = 2 * (y == 1) - 1  # Converts 0 -> -1 and 1 -> 1\n",
    "        print(f\"Filtered for binary classification (0 vs 1). Data shape: {X.shape}\")\n",
    "    else:\n",
    "        print(f\"Using multiclass classification (0-9). Data shape: {X.shape}\")\n",
    "\n",
    "    # Split data into training and testing sets BEFORE scaling/PCA\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=train_size, test_size=test_size, random_state=random_state, shuffle=True # Ensure split is shuffled\n",
    "    )\n",
    "\n",
    "    print(f\"Split complete. Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "    # Scale the features (Fit on training data only!)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test) # Transform test data using training scaler\n",
    "\n",
    "    # Reduce dimensionality using PCA (Fit on training data only!)\n",
    "    # Add random_state to PCA if using randomized solvers like 'arpack' or 'randomized'\n",
    "    pca = PCA(n_components=n_features, random_state=random_state) \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test) # Transform test data using training PCA\n",
    "\n",
    "    print(f\"PCA complete. Number of features: {X_train.shape[1]}\")\n",
    "    print(f\"Final Training size: {len(X_train)}, Final Test size: {len(X_test)}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfef642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running QSVM with 300 samples and 20.0% test data.\n",
      "Attempting to use PennyLane device: lightning.gpu\n",
      "Using multiclass classification (0-9). Data shape: (1797, 64)\n",
      "Split complete. Training samples: 300, Test samples: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA complete. Number of features: 10\n",
      "Final Training size: 300, Final Test size: 100\n"
     ]
    }
   ],
   "source": [
    "# Use lightning.gpu for GPU-accelerated simulations with PennyLane-Lightning\n",
    "# Ensure you have PennyLane-Lightning[GPU] and cuQuantum installed,\n",
    "# and a compatible CUDA toolkit and NVIDIA driver.\n",
    "QML_DEVICE = \"lightning.gpu\"\n",
    "\n",
    "def get_kernel_circuit(n_wires):\n",
    "    \"\"\"\n",
    "    Defines the quantum kernel circuit using PennyLane.\n",
    "    \"\"\"\n",
    "    # Uses lightning.gpu for GPU acceleration\n",
    "    dev = qml.device(QML_DEVICE, wires=n_wires, shots=None)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(x1, x2):\n",
    "        qml.IQPEmbedding(x1, wires=range(n_wires), n_repeats=4)\n",
    "        qml.adjoint(qml.IQPEmbedding)(x2, wires=range(n_wires), n_repeats=4)\n",
    "        return qml.probs(wires=range(n_wires))\n",
    "\n",
    "    return lambda x1, x2: circuit(x1, x2)[0]  # Return probability of |0...0> state\n",
    "\n",
    "def get_split_data(n_samples=18, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Generates and splits a synthetic dataset.\n",
    "    \"\"\"\n",
    "    centers = [(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]\n",
    "    X, y = make_blobs(n_samples, n_features=10, centers=centers, cluster_std=0.25, shuffle=False, random_state=42) # Added random_state for reproducibility\n",
    "    # Rescale labels to be -1, 1\n",
    "    mapping = {0: -1, 1: 1, 2: -1, 3: 1, 4: -1, 5: 1, 6: -1, 7: 1, 8: -1}\n",
    "    y = np.array([mapping[i] for i in y])\n",
    "    X = X.astype(np.float32)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=3)\n",
    "\n",
    "DISP_SETTINGS = {\n",
    "    \"grid_resolution\": 50,\n",
    "    \"response_method\": \"predict\",\n",
    "    \"alpha\": 0.5,\n",
    "    \"cmap\": plt.cm.RdBu,\n",
    "}\n",
    "\n",
    "def classify_with_qsvm(Xtr, Xte, ytr, yte, n_wires_for_kernel):\n",
    "    \"\"\"\n",
    "    Trains a QSVM classifier and evaluates it.\n",
    "    \"\"\"\n",
    "    kernel = get_kernel_circuit(n_wires=n_wires_for_kernel)\n",
    "\n",
    "    kernel_matrix_fn = lambda X, Z: qml.kernels.kernel_matrix(X, Z, kernel)\n",
    "    svc = SVC(kernel=kernel_matrix_fn).fit(Xtr, ytr)\n",
    "\n",
    "    # Train/test accuracy\n",
    "    accuracy_tr = svc.score(Xtr, ytr)\n",
    "    accuracy_te = svc.score(Xte, yte)\n",
    "\n",
    "    return accuracy_tr, accuracy_te\n",
    "\n",
    "def run_qsvm_local(n_samples, test_size):\n",
    "    \"\"\"\n",
    "    Main workflow to run the QSVM classification.\n",
    "    \"\"\"\n",
    "    Xtr, Xte, ytr, yte = prepare_digits_data_split(train_size=300, test_size=100, n_features=10)\n",
    "    # Xtr, Xte, ytr, yte = get_split_data(n_samples, test_size)\n",
    "    # The number of wires should match the number of features in the data\n",
    "    n_wires_for_kernel = Xtr.shape[1]\n",
    "    return classify_with_qsvm(Xtr, Xte, ytr, yte, n_wires_for_kernel)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Parameters for the QSVM\n",
    "    num_samples = 300\n",
    "    test_set_size = 0.2\n",
    "\n",
    "    print(f\"Running QSVM with {num_samples} samples and {test_set_size*100}% test data.\")\n",
    "    print(f\"Attempting to use PennyLane device: {QML_DEVICE}\")\n",
    "    start_time = time.time()\n",
    "    train_acc, test_acc = run_qsvm_local(\n",
    "        n_samples=num_samples,\n",
    "        test_size=test_set_size\n",
    "    )\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Train accuracy: {train_acc * 100:.1f}%\")\n",
    "    print(f\"Test accuracy: {test_acc * 100:.1f}%\")\n",
    "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
    "    # Show the plot\n",
    "    # plt.title(\"QSVM Decision Boundary\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "Xtr, Xte, ytr, yte = prepare_digits_data_split(train_size=300, test_size=100, n_features=10)\n",
    "start_time = time.time()\n",
    "qsvc = QSVC()\n",
    "qsvc.fit(Xtr, ytr)\n",
    "y_pred = qsvc.predict(Xte)\n",
    "execution_time = time.time() - start_time\n",
    "print(accuracy_score(yte, y_pred))\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cutn-qsvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
