{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running GPU-accelerated quantum circuit simulations on Covalent Cloud\nusing PennyLane\n===================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we'll demonstrate how to run GPU-accelerated quantum\ncircuit simulations on [Covalent Cloud](https://www.covalent.xyz) using\nPennyLane. We will focus on a specific example around quantum support\nvector machines (QSVMs) to demonstrate how easy it is to run\nGPU-accelerated quantum circuit simulations on Covalent Cloud.\n\nQSVMs are essentially [traditional\nSVMs](https://en.wikipedia.org/wiki/Support_vector_machine) that rely on\n[embedding\nkernels](https://en.wikipedia.org/wiki/Kernel_method#Mathematics:_the_kernel_trick)\nevaluated on a quantum computer---a.k.a. [quantum embedding\nkernel](https://pennylane.ai/qml/demos/tutorial_kernels_module/#training-and-evaluating-quantum-kernels).\nThese kernels provide a unique (and perhaps classically intractable)\nmeans of measuring pairwise similarity.\n\nUsing GPUs to simulate quantum computers is worthwhile when qubit\ncapacity and/or fidelity requirements are not met by the available\nquantum hardware. While QSVMs are relatively tolerant to noise (an\nimportant reason for their current popularity), evaluating kernels on\n*real* quantum hardware is not always practical nor necessary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementation\n\nLet's start by importing the required packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import covalent as ct\nimport covalent_cloud as cc\nimport matplotlib.pyplot as plt\nimport pennylane as qml\nfrom matplotlib.colors import ListedColormap\nfrom pennylane import numpy as np\nfrom sklearn.datasets import make_blobs\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\n\n# cc.save_api_key(\"YOUR_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Covalent Cloud allows us to create [reusable execution\nenvironments](https://docs.covalent.xyz/docs/cloud/guides/cloud_custom_environments/),\nas shown below. This environment represents a typical setup for running\nPennylane on NVIDIA GPUs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cc.create_env(\n    name=\"pennylane-gpu\",  # identifier for referring to this environment\n    conda={\n        \"channels\": [\"conda-forge\"],\n        \"dependencies\": [\"cudatoolkit>=11.8\"],\n    },\n    pip=[\n        \"cuquantum==23.10.0\",\n        \"matplotlib==3.8.2\",\n        \"Pennylane==0.34.0\",\n        \"PennyLane-Lightning[GPU]==0.34.0\",\n        \"scikit-learn==1.3.1\",\n        \"torch==2.1.2\",\n    ],\n    wait=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> > Waiting for environment pennylane-gpu to be\n> > ready\\...\\...\\...\\...\\...\\... Name: pennylane-gpu Status: READY\n> > Estimated Time: 1002 seconds Notes: pip was added to the\n> > dependencies. Python version 3.10 was added to the dependencies.\n> > Environment file contains: ========================== channels: -\n> > conda-forge dependencies: - python=3.10 - pip - cudatoolkit\\>=11.8 -\n> > pip: - cuquantum==23.10.0 - matplotlib==3.8.2 - Pennylane==0.34.0 -\n> > PennyLane-Lightning\\[GPU\\]==0.34.0 - scikit-learn==1.3.1 -\n> > torch==2.1.2 - covalent-cloud name: pennylane-gpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll define our resource specifications by creating some\n[executors](https://docs.covalent.xyz/docs/user-documentation/api-reference/executors/cloud_executor)\nfor this workflow. Both executors will run tasks in our new environment,\nnamed `\u201dpennylane-gpu\u201d`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cpu_executor = cc.CloudExecutor(  # for lightweight non-quantum tasks\n    env=\"pennylane-gpu\",\n    num_cpus=2,\n    memory=\"2GB\",\n)\ngpu_executor = cc.CloudExecutor(  # for GPU-powered circuit simulations\n    env=\"pennylane-gpu\", num_cpus=4, memory=\"12GB\", num_gpus=1, gpu_type=\"v100\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On to the algorithm!\n\nHere's a function returns a simple quantum kernel based on Pennylane's\n[IQP\nEmbedding](https://docs.pennylane.ai/en/stable/code/api/pennylane.IQPEmbedding.html)\ntemplate. We'll use it as-is inside our workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "QML_DEVICE = \"lightning.qubit\"\n\n\ndef get_kernel_circuit(n_wires):\n\n    @qml.qnode(qml.device(QML_DEVICE, wires=n_wires, shots=None))\n    def circuit(x1, x2):\n        qml.IQPEmbedding(x1, wires=range(n_wires), n_repeats=4)\n        qml.adjoint(qml.IQPEmbedding)(x2, wires=range(n_wires), n_repeats=4)\n        return qml.probs(wires=range(n_wires))\n\n    return lambda x1, x2: circuit(x1, x2)[0]  # |0..0> state probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, each function destined for remote execution is decorated with\n`@ct.electron`, with an\n[executor](https://docs.covalent.xyz/docs/user-documentation/api-reference/executors/cloud_executor)\nspecified therein. Only tasks that evaluate the simulated quantum kernel\nshould require `gpu_executor`. For example, we don't need GPUs to\ngenerate our input data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@ct.electron(executor=cpu_executor)  # lightweight non-quantum task\ndef get_split_data(n_samples=18, test_size=0.2):\n    centers = [(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]\n    X, y = make_blobs(n_samples, centers=centers, cluster_std=0.25, shuffle=False)\n    # rescale labels to be -1, 1\n    mapping = {0: -1, 1: 1, 2: -1, 3: 1, 4: -1, 5: 1, 6: -1, 7: 1, 8: -1}\n    y = np.array([mapping[i] for i in y])\n    X = X.astype(np.float32)\n    y = y.astype(int)\n\n    # X_train, X_test, y_train, y_test\n    return train_test_split(X, y, test_size=test_size, random_state=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classifying with the SVM, on the other hand, requires $O(n^2)$ kernel\nevaluations, where $n$ is the dataset size. Accordingly, we'll use GPUs\n(i.e.\u00a0`gpu_executor`) to speed up this process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "DISP_SETTINGS = {\n    \"grid_resolution\": 50,\n    \"response_method\": \"predict\",\n    \"alpha\": 0.5,\n    \"cmap\": plt.cm.RdBu,\n}\n\n\n@ct.electron(executor=gpu_executor)\ndef classify_with_qsvm(Xtr, Xte, ytr, yte):\n    kernel = get_kernel_circuit(n_wires=Xtr.shape[1])\n\n    kernel_matrix_fn = lambda X, Z: qml.kernels.kernel_matrix(X, Z, kernel)\n    svc = SVC(kernel=kernel_matrix_fn).fit(Xtr, ytr)\n\n    # train/test accuracy\n    accuracy_tr = svc.score(Xtr, ytr)\n    accuracy_te = svc.score(Xte, yte)\n\n    # decision boundary\n    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n    disp = DecisionBoundaryDisplay.from_estimator(svc, Xte, **DISP_SETTINGS)\n    disp.ax_.scatter(Xtr[:, 0], Xtr[:, 1], c=ytr, cmap=cm_bright)\n    disp.ax_.scatter(Xte[:, 0], Xte[:, 1], c=yte, cmap=cm_bright, marker=\"$\\u25EF$\")\n\n    return accuracy_tr, accuracy_te, disp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Putting it all together, we can define a QSVM training and testing\nworkflow. This special function gets decorated with `@ct.lattice`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@ct.lattice(workflow_executor=cpu_executor, executor=cpu_executor)\ndef run_qsvm(n_samples, test_size):\n    Xtr, Xte, ytr, yte = get_split_data(n_samples, test_size)\n    return classify_with_qsvm(Xtr, Xte, ytr, yte)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, to dispatch `run_qsvm` to Covalent Cloud, we call it after wrapping\nwith `ct.dispatch`, as usual.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dispatch_id = cc.dispatch(run_qsvm)(n_samples=64, test_size=0.2)\nprint(\"Dispatch ID:\", dispatch_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> > Dispatch ID: 0b5d3a08-fe9c-4dc2-910b-0be6eb925663\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's what we get when we query and display the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result = cc.get_result(dispatch_id, wait=True)\nresult.result.load()\n\ntrain_acc, test_acc, decision_boundary_figure = result.result.value\nprint(f\"Train accuracy: {train_acc * 100:.1f}%\")\nprint(f\"Test accuracy: {test_acc * 100:.1f}%\")\n\ndecision_boundary_figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> > Train accuracy: 64.7% Test accuracy: 76.9%\n\n![](../_static/demonstration_assets/covalent_cloud_gpu/covalent_cloud_gpu_19_1.png){.align-center\nwidth=\"90.0%\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n\nIn this tutorial, we demonstrated how to run quantum circuit simulations\non GPUs via Covalent Cloud. We used PennyLane to define a simple quantum\nkernel, and then trained and tested a QSVM on a 2-dimensional dataset.\nTo make the most of this tutorial, try experimenting with different\ndatasets/kernels or increasing the dataset dimension, to gain a greater\nadvantage from GPU acceleration.\n\nThe cost of running this workflow is approximately \\$0.27. The full code\nis available below, and you can try it yourself with the *Run on\nCovalent Cloud* button in the side menu on the right.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Full Code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``` python\nimport covalent as ct\nimport covalent_cloud as cc\nimport matplotlib.pyplot as plt\nimport pennylane as qml\nfrom matplotlib.colors import ListedColormap\nfrom pennylane import numpy as np\nfrom sklearn.datasets import make_blobs\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\n\ncc.save_api_key(\"API_KEY\")\n\ncc.create_env(\n    name=\"pennylane-gpu\",  # identifier for referring to this environment\n    conda={\n        \"channels\": [\"conda-forge\"],\n        \"dependencies\": [\"cudatoolkit>=11.8\"],\n    }, pip=[\n        \"cuquantum==23.10.0\",\n        \"matplotlib==3.8.2\",\n        \"Pennylane==0.34.0\",\n        \"PennyLane-Lightning[GPU]==0.34.0\",\n        \"scikit-learn==1.3.1\",\n        \"torch==2.1.2\",\n    ],\n    wait=True\n)\n\ncpu_executor = cc.CloudExecutor(  # for lightweight non-quantum tasks\n    env=\"pennylane-gpu\",\n    num_cpus=2,\n    memory=\"2GB\",\n)\ngpu_executor = cc.CloudExecutor(  # for GPU-powered circuit simulations\n    env=\"pennylane-gpu\",\n    num_cpus=4,\n    memory=\"12GB\",\n    num_gpus=1,\n    gpu_type=\"v100\"\n)\n\nQML_DEVICE = \"lightning.gpu\"\n\ndef get_kernel_circuit(n_wires):\n\n    @qml.qnode(qml.device(QML_DEVICE, wires=n_wires, shots=None))\n    def circuit(x1, x2):\n        qml.IQPEmbedding(x1, wires=range(n_wires), n_repeats=4)\n        qml.adjoint(qml.IQPEmbedding)(x2, wires=range(n_wires), n_repeats=4)\n        return qml.probs(wires=range(n_wires))\n\n    return lambda x1, x2: circuit(x1, x2)[0]  # |0..0> state probability\n\n@ct.electron(executor=cpu_executor)  # lightweight non-quantum task\ndef get_split_data(n_samples=18, test_size=0.2):\n    centers = [(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]\n    X, y = make_blobs(n_samples, centers=centers, cluster_std=0.25, shuffle=False)\n    # rescale labels to be -1, 1\n    mapping = {0: -1, 1: 1, 2: -1, 3: 1, 4: -1, 5: 1, 6: -1, 7: 1, 8: -1}\n    y = np.array([mapping[i] for i in y])\n    X = X.astype(np.float32)\n    y = y.astype(int)\n\n    # X_train, X_test, y_train, y_test\n    return train_test_split(X, y, test_size=test_size, random_state=3)\n\nDISP_SETTINGS = {\"grid_resolution\": 50, \"response_method\": \"predict\", \"alpha\": 0.5, \"cmap\": plt.cm.RdBu}\n\n@ct.electron(executor=gpu_executor)\ndef classify_with_qsvm(Xtr, Xte, ytr, yte):\n    kernel = get_kernel_circuit(n_wires=Xtr.shape[1])\n\n    kernel_matrix_fn = lambda X, Z: qml.kernels.kernel_matrix(X, Z, kernel)\n    svc = SVC(kernel=kernel_matrix_fn).fit(Xtr, ytr)\n\n    # train/test accuracy\n    accuracy_tr = svc.score(Xtr, ytr)\n    accuracy_te = svc.score(Xte, yte)\n\n    # decision boundary\n    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n    disp = DecisionBoundaryDisplay.from_estimator(svc, Xte, **DISP_SETTINGS)\n    disp.ax_.scatter(Xtr[:, 0], Xtr[:, 1], c=ytr, cmap=cm_bright)\n    disp.ax_.scatter(Xte[:, 0], Xte[:, 1], c=yte, cmap=cm_bright, marker=\"$\\u25EF$\")\n\n    return accuracy_tr, accuracy_te, disp\n\n@ct.lattice(workflow_executor=cpu_executor, executor=cpu_executor)\ndef run_qsvm(n_samples, test_size):\n    Xtr, Xte, ytr, yte = get_split_data(n_samples, test_size)\n    return classify_with_qsvm(Xtr, Xte, ytr, yte)\n\ndispatch_id = cc.dispatch(run_qsvm)(n_samples=64, test_size=0.2)\nprint(\"Dispatch ID:\", dispatch_id)\n\nresult = cc.get_result(dispatch_id, wait=True)\nresult.result.load()\n\ntrain_acc, test_acc, decision_boundary_figure = result.result.value\nprint(f\"Train accuracy: {train_acc * 100:.1f}%\")\nprint(f\"Test accuracy: {test_acc * 100:.1f}%\")\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# About the author\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}